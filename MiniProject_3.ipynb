{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "MiniProject_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/du-hr/MNIST-CNN/blob/good_copy/MiniProject_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4oL3OOWmdmj"
      },
      "source": [
        "# MiniProject 3: Multi-label Classification of Image Data\n",
        "\n",
        "\n",
        "> MiniProject 3 of COMP 551 (Fall 2020) at McGill University\n",
        "\n",
        "\n",
        "> Authors (G17): Haoran Du (260776911), Robin Cho (260806783), Teresa Lee (260715070)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CRaxVKWmgLT"
      },
      "source": [
        "import numpy as np\n",
        "import scipy as sci\n",
        "import pandas as pd\n",
        "import h5py\n",
        "import torch\n",
        "from google.colab import drive\n",
        "# ignore the follwoing line if running locally\n",
        "drive.mount('/content/drive')\n",
        "# make path = './' if running locally\n",
        "path = '/content/drive/My Drive/'\n",
        "\n",
        "#%matplotlib notebook\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUzwim-Zm_Kq"
      },
      "source": [
        "## **1. Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhoZNvWEmes0"
      },
      "source": [
        "### **1.1 Import Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm21qXxGmppM"
      },
      "source": [
        "# load the datasets\n",
        "with h5py.File(path+'MNIST_synthetic.h5', 'r') as hdfid:\n",
        "     print(hdfid.keys())\n",
        "     test_images = hdfid['test_dataset'][()]\n",
        "     train_images = hdfid['train_dataset'][()]\n",
        "     train_labels = hdfid['train_labels'][()]\n",
        "\n",
        "# display train_images properties\n",
        "print(train_images.shape)\n",
        "# print(train_iamges[10][30])\n",
        "\n",
        "# plot first 3 images in train_images\n",
        "images=[]\n",
        "titles=[]\n",
        "images.append(np.array(train_images[0], dtype='float').reshape(64,64))\n",
        "titles.append(\"img_1\")\n",
        "images.append(np.array(train_images[1], dtype='float').reshape(64,64))\n",
        "titles.append(\"img_2\")\n",
        "images.append(np.array(train_images[2], dtype='float').reshape(64,64))\n",
        "titles.append(\"img_3\")\n",
        "\n",
        "for i in range(3):\n",
        "    plt.subplot(1,3,i+1),plt.imshow(images[i])\n",
        "    plt.title(titles[i])\n",
        "    plt.xticks([]),plt.yticks([])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# display train_labels properties\n",
        "print(train_labels.shape)\n",
        "print(train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQktZ_BjmtOM"
      },
      "source": [
        "### **1.2 Class Distribution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzyQSMQSmwjX"
      },
      "source": [
        "unique_y1, counts_y1 = np.unique(train_labels[:, 0], return_counts=True)\n",
        "plt.bar(unique_y1, counts_y1/sum(counts_y1))\n",
        "plt.xticks(unique_y1, unique_y1)\n",
        "plt.title(f\"Class Distribution of the first column\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZbIo0WimxFs"
      },
      "source": [
        "unique_y2, counts_y2 = np.unique(train_labels[:, 1], return_counts=True)\n",
        "plt.bar(unique_y2, counts_y2/sum(counts_y2))\n",
        "plt.xticks(unique_y2, unique_y2)\n",
        "plt.title(f\"Class Distribution of the second column\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KnftLM3mxZ-"
      },
      "source": [
        "unique_y3, counts_y3 = np.unique(train_labels[:, 2], return_counts=True)\n",
        "plt.bar(unique_y3, counts_y3/sum(counts_y3))\n",
        "plt.xticks(unique_y3, unique_y3)\n",
        "plt.title(f\"Class Distribution of the third column\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9fm69_-mxq6"
      },
      "source": [
        "unique_y4, counts_y4 = np.unique(train_labels[:, 3], return_counts=True)\n",
        "plt.bar(unique_y4, counts_y4/sum(counts_y4))\n",
        "plt.xticks(unique_y4, unique_y4)\n",
        "plt.title(f\"Class Distribution of the fourth column\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsutla-Lmx_f"
      },
      "source": [
        "unique_y5, counts_y5 = np.unique(train_labels[:, 4], return_counts=True)\n",
        "plt.bar(unique_y5, counts_y5/sum(counts_y5))\n",
        "plt.xticks(unique_y5, unique_y5)\n",
        "plt.title(f\"Class Distribution of the fifth column\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZJuyGO-m7UR"
      },
      "source": [
        "## **2. First Approach**\n",
        "Train a mult-label classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKq3hxAzm6VI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q1MHNcbnkA5"
      },
      "source": [
        "## **3. Second Approach**\n",
        "Partition the images and train a single label classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iQspd5_nh9H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFjwUmC-n1pz"
      },
      "source": [
        "## **4. Application to Testing Images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_UihPVin7G0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}